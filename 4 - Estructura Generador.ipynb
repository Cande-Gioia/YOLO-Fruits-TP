{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bruno\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.16). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from detection_helper import create_DF\n",
    "from matplotlib import pyplot as plt\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "import matplotlib.patches as patches\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = list(Path(\"Dataset/train/\").glob(\"**/*txt\"))\n",
    "val_files = list(Path(\"Dataset/validation/\").glob(\"**/*txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = create_DF(train_files,Path(\"Dataset/train/Apple_Grape_Cantaloupe_Watermelon_Pomegranate_Pineapple_Peach_Mango_Banana_Lemon_Tomato_Strawberry_Pear/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_hdf(\"df_train.hdf\", key=\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, df, albumentator, anchor_boxes, IoU_alpha=0.5, batch_size=32, crop_size=[512,512], grid_size=[32,32]):\n",
    "        'Initialization'\n",
    "        self.df = df.copy()\n",
    "        self.albumentator = albumentator\n",
    "        self.anchor_boxes = anchor_boxes\n",
    "        self.cant_anchor_boxes = len(self.anchor_boxes)\n",
    "        self.IoU_alpha = IoU_alpha\n",
    "        self.batch_size = batch_size\n",
    "        self.crop_size = [512,512]\n",
    "        self.grid_size = [32,32]\n",
    "        self.classes = self.df[\"label\"].unique()\n",
    "        self.classes.sort()\n",
    "        self.classes_idx = {clase:idx for idx,clase in enumerate(self.classes)}\n",
    "        self.cant_classes = len(self.classes)\n",
    "        self.list_IDs = self.df[\"image_name\"].unique()\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        print(list_IDs_temp)\n",
    "        return 1,1\n",
    "#         # Initialization\n",
    "#         X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "#         y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "#         # Generate data\n",
    "#         for i, ID in enumerate(list_IDs_temp):\n",
    "#             # Store sample\n",
    "#             X[i,] = np.load('data/' + ID + '.npy')\n",
    "\n",
    "#             # Store class\n",
    "#             y[i] = self.labels[ID]\n",
    "\n",
    "#         return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"anchor_boxes.pkl\", \"rb\") as f:\n",
    "    anchor_boxes = pickle.load(f)\n",
    "cant_anchor_boxes = len(anchor_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.RandomCrop(width=512, height=512),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "], bbox_params=A.BboxParams(format='coco', min_area=1024, min_visibility=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = DataGenerator(df_train,transform,anchor_boxes=anchor_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['76d74e8afd19313e', '20d53a3143fa41b8', '9bb208229bfd7175', 'ef16b1f81560c0bd', 'fdc1fc0d417075ea', '11a15fcf7426166d', '655416f183f629ce', '48fd868dbe1f524a', 'f9c7d16af494c212', '00d1a44121b1b883', '07d482fa22194c70', '1f76ac5e32b66c76', 'e1805a3977f44cfb', '02fb78b224bc4418', 'd80173d01625b2fa', '1ba8191d864987f4', 'ddf1c169ae6805f5', 'ae2931c5820d4f3d', '8c981905e54c01c0', '0dc8a1ebc366a5c1', '8a8d9e65261f0cc3', 'f9a6f4038890276a', '00730e60ab276b06', '87e88ea71a9c8a71', 'bb2dd21db373a147', '811523dbfba99205', '0e5b1f1a294fad14', 'd0a8c3d2707ede8e', '2c7ed825d739673d', '32229d0bed0d5181', 'a3a598da5c9e1c2c', '4a9d7d2790403b67']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
